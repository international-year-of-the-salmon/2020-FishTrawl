---
title: "data_wrangle_trawl"
author: "Tim van der Stap & Julian Gan"
date: "5/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
library(tidyverse)
library(lubridate)
library(readxl)
library(here)
library(worrms)
library(obistools)
library(parsedate)
library(googledrive)
library(uuid)
```

The first step is to download the files from GoogleDrive and save it in a local folder. One file contains the bridgelog data and aggregated data, whereas the other contains specimen-specific catch measurements. 

``` {r file_download}
drive_download(file = "https://docs.google.com/spreadsheets/d/1xm_MIx_y8nsvA8I-7G33RcQ_j7w-Qmm-/edit#gid=168338968", 
               path = here::here("Trawl", "raw_data", "2020_GoA_Fish_Trawl_data.xlsx"),
               overwrite = TRUE)

drive_download(file = "https://docs.google.com/spreadsheets/d/1m_o8Ux3s-0CS4rE3CP7cT3kFOY4-e97B/edit#gid=1644980763",
               path = here::here("Trawl", "raw_data", "2020_GoA_Fish_Specimen_data.xlsx"),
               overwrite = TRUE)
```

The trawl data is read from the local folder, and the date/time is formatted to the ISO 8601 standards. Additionally, five layers are created to populate the event Core: "project", "cruise", "station", "trawl" and "sample". Following the discussion [here](https://github.com/iobis/env-data/issues/10), data on total species' catch biomass gets linked to the `trawl` layer (through an `occurrenceID`) in the Event Core, whereas individual fish measurements get linked the `sample` layer (see diagram [here](https://lucid.app/lucidchart/a1d199b4-ef42-45fc-a384-273925fef7d7/edit?page=0_0#?folder_id=home&browser=icon)). The fish trawl abundance data file also includes the bridgelog file sheet, where metadata is recorded. When reading the data in from the local folder make sure that a clear distinction is made between the bridgelog (metadata) and the catch data. 

``` {r trawl_data_prep, eval = FALSE, warning = FALSE}
trawl2020 <- read_excel(here("Trawl", "2020", "raw_data", "2020_GoA_Fish_Trawl_data.xlsx"), sheet = "BRIDGE_LOG_FINAL") %>%
  mutate(Time = format(TIME_FISHING_START, "%H:%M:%S"),
         eventDate = format_iso_8601(as.POSIXct(paste(EVENT_DATE, Time),
                                                format = "%Y-%m-%d %H:%M:%S",
                                                tz = "Asia/Kamchatka")), # Confirm this timezone. 
         eventDate = str_replace(eventDate, "\\+00:00", "Z"),
         project = "IYS",
         cruise = paste(project, "GoA2020", sep = ":"), 
         station = paste(cruise, SET_NUMBER, sep=":Stn"),
         trawl = paste(station, "trawl", sep=":"))

# For OBIS it is useful to parse the eventDate and extract year, month and day from it, for visualizations purposes.
trawl2020$year <- as.numeric(format(as.Date(trawl2020$eventDate), "%Y"))
trawl2020$month <- as.numeric(format(as.Date(trawl2020$eventDate), "%m"))
trawl2020$day <- as.numeric(format(as.Date(trawl2020$eventDate), "%d"))

trawl2020_allCatch <- read_excel(here("Trawl", "2020", "raw_data", "2020_GoA_Fish_Trawl_data.xlsx"), sheet = "CATCH_FINAL") %>%
  mutate(project = "IYS",
         cruise = paste(project, "GoA2020", sep = ":"),
         station = paste(cruise, `SET_NUMBER`, sep = ":Stn"),
         trawl = paste(station, "trawl", sep = ":"))

trawl2020_specimen <- read_excel(here("Trawl", "2020", "raw_data", "2020_GoA_Fish_Specimen_data.xlsx"), 
                                 sheet = "SPECIMEN_FINAL") %>%
  mutate(project = "IYS",
         cruise = paste(project, "GoA2020", sep = ":"),
         station = paste(cruise, SET_NUMBER, sep = ":Stn"),
         trawl = paste(station, "trawl", sep = ":"),
         sample = paste(trawl, "sample", sep = ":"),
         sample = paste(sample, row_number(), sep = ":"))
```

***

## Event Core 

Next, dataframes are created for each unique `eventID` layer, with unique associated columns. Eventually, the data frames get joined, and the eventCore gets saved locally and in Google Drive. The column `eventRemarks` is not a required column, but includes descriptive information pertaining to any issues that arose during the setting of the trawl net. 

``` {r trawl_event, eval = FALSE}
trawl2020_project <- trawl2020 %>%
  select(eventID = project) %>%
  distinct(eventID) %>%
  mutate(type = "project")

trawl2020_cruise <- trawl2020 %>% 
  select(eventID = cruise,
         parentEventID = project) %>% 
  distinct(eventID, .keep_all = TRUE) %>%
  mutate(type = "cruise")

trawl2020_station <- trawl2020 %>% 
  select(eventID = station,
         parentEventID = cruise) %>% 
  distinct(eventID, .keep_all = TRUE) %>%
  mutate(type = "station")

# The coordinates associated to the trawl need to be presented in a LINESTRING:
trawl2020_coordinates <- trawl2020 %>%
  select(eventID = trawl,
         START_LAT_DECDEGREE,
         START_LONG_DECDEGREE,
         END_LAT_DECDEGREE,
         END_LONG_DECDEGREE) %>%
  mutate(footprintWKT = paste("LINESTRING (", START_LONG_DECDEGREE, START_LAT_DECDEGREE, ",", 
                              END_LONG_DECDEGREE, END_LAT_DECDEGREE, ")")) %>%
  filter(!is.na(END_LAT_DECDEGREE)) # Station 20 needs end lat and long included - this issue needs to be resolved. 

trawl2020_linestring <- obistools::calculate_centroid(trawl2020_coordinates$footprintWKT)
trawl2020_linestring <- cbind(trawl2020_coordinates, trawl2020_linestring) %>%
  select(eventID, footprintWKT, decimalLatitude, decimalLongitude, coordinateUncertaintyInMeters)

trawl2020_trawl <- trawl2020 %>% 
  select(eventID = trawl,
         parentEventID = station,
         eventDate,
         year,
         month,
         day,
         fieldNotes = PROBLEM_DESCRIPTION) %>%
  mutate(minimumDepthInMeters = 0, # trawl was at the surface
         maximumDepthInMeters = pmax(trawl2020$`NET OPENING DEPTH (metres) - 15 min`,
                                     trawl2020$`NET OPENING DEPTH (metres) - 30 min`,
                                     trawl2020$`NET OPENING DEPTH (metres) - 45 min`,
                                     trawl2020$`NET OPENING DEPTH (metres) - END`, na.rm = TRUE),
         samplingProtocol = "midwater trawl", # if possible add DOI to paper here
         locality = case_when(
           trawl2020$LOCATION == "GoA" ~ "Gulf of Alaska",
           trawl2020$LOCATION == "Canadian EEZ" ~ "Canadian EEZ"),
         locationID = case_when(
           trawl2020$LOCATION == "Canadian EEZ" ~ "http://marineregions.org/mrgid/8493")) %>%
  left_join(trawl2020_linestring, by = "eventID") %>% 
  distinct(eventID, .keep_all = TRUE) %>%
    mutate(type = "midwater trawl")
  
trawl2020_sample <- trawl2020_specimen %>%
  select(eventID = sample,
         parentEventID = trawl) %>%
  distinct(eventID, .keep_all = TRUE) %>%
  mutate(type = "individual sample")

trawl2020_event <- bind_rows(trawl2020_project, 
                             trawl2020_cruise,
                             trawl2020_station,
                             trawl2020_trawl,
                             trawl2020_sample) 

col_order <- c("eventID", "parentEventID", "eventDate", "year", "month", "day", "decimalLatitude", "decimalLongitude", "footprintWKT", "coordinateUncertaintyInMeters", "minimumDepthInMeters", "maximumDepthInMeters", "samplingProtocol", "locality", "locationID", "type", "fieldNotes")
trawl2020_event <- trawl2020_event[, col_order]

# Flatten event records:
trawl2020_event <- obistools::flatten_event(trawl2020_event)

# Remove NA and replace with empty cells:
trawl2020_event <- sapply(trawl2020_event, as.character)
trawl2020_event[is.na(trawl2020_event)] <- ""
trawl2020_event <- as.data.frame(trawl2020_event)

# Check if eventIDs are all unique - should be TRUE:
length(unique(trawl2020_event$eventID)) == nrow(trawl2020_event)

write_csv(trawl2020_event, here("Trawl", "2020", "tidy_data", "trawl2020_event.csv"))
drive_upload(here("Trawl", "tidy_data", "trawl_event.csv"),
             path = "",
             name = "trawl_event.csv",
             overwrite = TRUE)
```

***

## Occurrence extension

As the trawl data consists of biotic data, an occurrence extension table has to be created as well, whereby unique `occurrenceIDs` get linked to the `eventID`. The `occurrenceID` is created from the `eventID`, and any measurements pertaining to the specific individual will be associated to that `occurrenceID` in the extended MeasurementOrFact (eMOF) extension.

The Occurrence extension will consist of two tables merged, one from the aggregated (summary) catch data (`catch_final`), and one from the individual length and weight measurements. There will be unique `occurrenceIDs` related to the trawl layer in event Core. Measurements associated with this `occurrenceID` will be total species' catch biomass and catch numbers. The `occurrenceID` for the aggregated catch data will have the format `IYS:GoA2020:Stn1:trawl:occ:1`. An additional layer in the event Core (sample) was created so that other unique `occurrenceIDs` can be linked to that layer, with `occurrenceIDs` having the format `IYS:GoA2020:Stn1:trawl:sample1:occ:1`. Measurements linked to these `occurrenceIDs` are individual length and biomass. Additionally, a column `occurrenceRemarks` will be included to indicate that that specific `occurrenceID` is a subset of the aggregated catch data. For discussion on how `occurrenceIDs` are linked to different layers, see [here](https://github.com/iobis/env-data/issues/10).

A required column for the Occurrence extension is the term, `occurrenceStatus`, which is used for presence/absence data. The package `worrms` is used to generate hierarchial taxonomic information on the species observed. For the `scientificNameID`, we look up the species on the WoRMS website (http://www.marinespecies.org/). 

Finally, we can do a quick check to make sure that all the unique species are included in the trawl_occ dataframe. We need to make sure that the output is TRUE. If confirmed, the Occurrence extension can be saved locally and in the correct Google Drive folder. We also need to make sure that if columns 'SPECIES' or 'SPECIES (Description if needed)' make mention of a lifestage, or sex, we need to include this in the occurrence extension. 

As discussed with the Data Provider (C. Neville), the standardized data will only include basic data (length, weight, sex and ageclass) for _larger_ species. As such, the data will be filtered for taxa that have been identified to a _species_ level, and have an associated catch count. The data will include species that have been counted (count_method is `total`) and where species count come from expanded numbers as well if these are based on standard processes (count_method is `volume_estimate`). **This eliminates catch counts that are based on `estimate -- unknown method` and `visual_estimate`, or where this field has been left blank**.

**IMPORTANT:** Please note, that when filtered following the above-mentioned criteria, there are still taxa records that _do not_ have an associated total catch weight.

``` {r trawl2020_occ, eval = FALSE}
# Species are only recorded in SPECIES column. To identify which taxa have not been identified to a species level, we extract the second word from the character string under SPECIES into a separate column: specificEpithet. 
trawl2020_allCatch$specificEpithet <- stringr::word(trawl2020_allCatch$SPECIES, 2)

# Drop rows where species is either "sp", "sp.", "eggs", or NA:
trawl2020_allCatch <- trawl2020_allCatch[!(trawl2020_allCatch$specificEpithet %in% c("sp", "sp.", "eggs", "larvae")), ]
trawl2020_allCatch <- trawl2020_allCatch[!is.na(trawl2020_allCatch$specificEpithet), ]

# Next, we filter for species that have been counted or whose numbers are based on standard processes (total, volume estimate), and that have a catch_number associated with the observation. It is important to note that LENGTH (N) cannot be a substitute for individualCount. However, by including this while filtering the data, it improves the understanding between all catch occurrence extension and the individual occurrence extension. Finally, sometimes the lifestage is included in the Species description. This needs to be extracted and included in a separate column (lifeStage). 
count_method <- c("total", "volume estimate")
trawl2020_allCatch <- trawl2020_allCatch %>% 
  filter(`COUNT_METHOD                 (Total, Volume est, Weight est)` %in% count_method) %>%
  filter(!is.na(CATCH_NUMBER))

trawl2020_allCatch <- trawl2020_allCatch %>%
  mutate(lifeStage = case_when(
    grepl("larvae", trawl2020_allCatch$`SPECIES (Description if needed)`) ~ "larvae")) %>%
  rename(scientificname = SPECIES)

trawl2020_allCatch_scientificnames <- worrms::wm_records_names(unique(trawl2020_allCatch$scientificname)) %>% bind_rows()
trawl2020_allCatch_taxa <- left_join(trawl2020_allCatch, trawl2020_allCatch_scientificnames, by = "scientificname")

# You'll notice that not all unique_taxa have associated taxonomic hierarchial information. Let's inspect these observations as they might be either misspelled, or a non-Latin name is provided. 
unidentified_species <- trawl2020_allCatch_taxa %>% filter(is.na(AphiaID)) %>% distinct(scientificname)
```

A total of 4 species could not be matched to a record within the WoRMS database. Most often this is due to spelling errors, or the lack of supplying a Latin name. I manually check these species in the WoRMS database and confirm with the data provider that the suggested species are the ones meant. These species will then be corrected in the trawl2020_allCatch_taxa data frame. 

**IMPORTANT:** Following a meeting with the data provider (C. Neville), we have agreed to only include the "larger" species in this standardized dataset. As such, in this script we are filtering out species from the catch that could not be identified to a species level, where no catch count has been recorded, or where the count method is estimated visually, via an unknown method, or not recorded (left blank). Then, confirm that the species listed and recorded in the Standardized Data are also included in the original data. Then, the occurrence extension is saved locally and in the correct Google Drive folder.

On this subset of data, change the taxa names to ensure they are matched with record in the WoRMS registry: 

``` {r, eval = FALSE}
# For the remaining species, use gsub to replace them with appropriate record in WoRMS. 
trawl2020_allCatch$scientificname <- gsub("Abraliopsis Felis", "Abraliopsis felis", trawl2020_allCatch$scientificname)
trawl2020_allCatch$scientificname <- gsub("Sergestes similus", "Sergestes similis", trawl2020_allCatch$scientificname)
trawl2020_allCatch$scientificname <- gsub("Gooseneck barnacle", "Pollicipes pollicipes", trawl2020_allCatch$scientificname)
trawl2020_allCatch$scientificname <- gsub("Chiroteuthis calix", "Chiroteuthis calyx", trawl2020_allCatch$scientificname)
trawl2020_allCatch$scientificname <- gsub("Glycptocephalus zacharius", "Glyptocephalus zachirus", trawl2020_allCatch$scientificname)
```

If we opt to not subset the data and include smaller taxa, taxa that were identified to a higher taxonomic rank than species or whose catch numbers have been estimated from volume or weight expansion, replace the last chunk of code with the following: 

``` {r, eval = FALSE}
# trawl2020_allCatch$scientificname <- mgsub::mgsub(trawl2020_allCatch$scientificname,
#                         c("Paralichthydidae", "Paralepidadae", "Sergestes similus", "Salps", "Abraliopsis Felis",
#                           "Euphausiid", "Gooseneck barnacle", "Chiroteuthis calix", "Glycptocephalus zacharius",
#                           "squid", "Fish eggs", "jellyfish", "myctophiids", "goose neck barnacle", "gonatidae",
#                           "Flatfish larvae", "Ptereotrachea"),
#                         c("Paralichthyidae", "Paralepidapedon", "Sergestes similis", "Salpa", "Abraliopsis felis",
#                           "Euphausiidae", "Pollicipes pollicipes", "Chiroteuthis calyx", "Glyptocephalus zachirus",
#                           "Teuthida", "Pisces", "Cnidaria", "Myctophidae", "Pollicipes pollicipes", "Gonatidae",
#                           "Pleuronectiformes", "Pterotrachea"))
```

So now we can run worrms::wm_records_names again, and there should be no NA in the AphiaID column. Additionally, we recreate the column `specificEpithet` that includes the species name, because in the previous chunk we made some minor changes to the species name. 

Finally, the occurrence extension for the overall catch is created and saved locally and on Google Drive: 

``` {r overall_catch_occ, eval = FALSE}
trawl2020_occ <- worrms::wm_records_names(unique(trawl2020_allCatch$scientificname)) %>% bind_rows()
trawl2020_occ <- left_join(trawl2020_allCatch, trawl2020_occ, by = "scientificname")

trawl2020_occ <- trawl2020_occ %>%
  mutate(specificEpithet = stringr::word(trawl2020_occ$scientificname, 2)) %>%
  rename(eventID = trawl,
         scientificNameAuthorship = authority,
         taxonomicStatus = status,
         taxonRank = rank,
         scientificName = scientificname,
         scientificNameID = lsid,
         individualCount = CATCH_NUMBER,
         occurrenceRemarks = Comments) %>%
  mutate(occurrenceID = paste(eventID, "occ", sep = ":"),
         occurrenceID = paste(occurrenceID, row_number(), sep = ":"),
         occurrenceStatus = "present",
         individualCount = round(individualCount),
         sex = NA) 

trawl2020_occ_fnl <- trawl2020_occ %>%
  select(eventID, occurrenceID, occurrenceStatus, individualCount, 
         scientificName, scientificNameID, scientificNameAuthorship, taxonomicStatus, 
         taxonRank, kingdom, phylum, class, order, family, genus, specificEpithet, lifeStage, sex, occurrenceRemarks)

# Save the occurrence extension locally and in Google Drive:
write_csv(trawl2020_occ_fnl, here("Trawl", "2020", "tidy_data", "trawl2020_occ_allCatch.csv"))
```

So now we have created the first Occurrence extension table, which includes the overall catch data. In the trawl2020_allCatch dataframe, column `Length (N)` indicates how many individuals at each trawl were measured for their lengths. In the next section, we create a second occurrence extension table, with `occurrenceID`s created for each unique individual whose length has been measured. Where the `occurrenceID` in the previous chunk of code has the format of `IYS:GoA2020:Stn1:trawl:occ:1`, the `occurrenceID`s in the next section will have the format `IYS:GoA2020:Stn1:trawl:occ:sample:1`. An additional extension will be created to indicate that the individual measurements are a subset of the overall catch at that station (`resourceRelationship` extension). 

First we have to ensure that for the individual data, we only include taxa that are also included in the standardized overall catch data:

``` {r occ_species, eval = FALSE}
# Create column specificEpithet. This will also allow us to filter for specimen that are identified to species level:
trawl2020_specimen$specificEpithet <- stringr::word(trawl2020_specimen$SPECIES, 2)
print(unique(trawl2020_specimen$specificEpithet))

# Drop rows where species is either "sp.", "larvae", "jelly" or NA. :
trawl2020_specimen <- trawl2020_specimen[!(trawl2020_specimen$specificEpithet %in% c("sp.", "larvae", "jelly")), ]
trawl2020_specimen <- trawl2020_specimen[!is.na(trawl2020_specimen$specificEpithet), ]
trawl2020_specimen <- trawl2020_specimen %>% rename(scientificname = SPECIES)

trawl2020_specimen_scientificnames <- worrms::wm_records_names(unique(trawl2020_specimen$scientificname)) %>% bind_rows()
trawl2020_specimen_taxa <- left_join(trawl2020_specimen, trawl2020_specimen_scientificnames, by = "scientificname")

# You'll notice that not all unique_taxa have associated taxonomic hierarchial information. Let's inspect these observations as they might be either misspelled, or a non-Latin name is provided. 
unidentified_specimen <- trawl2020_specimen_taxa %>% filter(is.na(AphiaID)) %>% distinct(scientificname)

# Change the names of the SPECIES as done previously in the overall catch data:
trawl2020_specimen$scientificname <- gsub("Phacellophoroa camtschatica", "Phacellophora camtschatica", trawl2020_specimen$scientificname)
trawl2020_specimen$scientificname <- gsub("Oncorhynchus gorbusha", "Oncorhynchus gorbuscha", trawl2020_specimen$scientificname)
trawl2020_specimen$scientificname <- gsub("Abraliopsis Felis", "Abraliopsis felis", trawl2020_specimen$scientificname)
trawl2020_specimen$scientificname <- gsub("Chiroteuthis calix", "Chiroteuthis calyx", trawl2020_specimen$scientificname)
trawl2020_specimen$scientificname <- gsub("Glycptocephalus zacharius", "Glyptocephalus zachirus", trawl2020_specimen$scientificname)

# Additionally, there is a species mentioned "Dosidicus gigas?". In the overall catch data this species is reported as Dosidicus gigas, so the question mark is removed from the trawl2020_specimen dataframe:
trawl2020_specimen$scientificname <- gsub("[[:punct:]]", "", trawl2020_specimen$scientificname)

# The trawl2020_allCatch data indicates how many individual specimen records were created (column: LENGTH (N)) from each taxonomic observation, so filter for those records where LENGTH (N) > 0:
station_specific_unique_taxa <- trawl2020_allCatch %>% filter(`LENGTH (N)` > 0 | `WEIGHT (N)` > 0) %>% select(trawl, scientificname)
trawl2020_specimen <- left_join(trawl2020_specimen, station_specific_unique_taxa, by = c("scientificname", "trawl"))
 
trawl2020_catch_ind <- trawl2020_specimen %>%
  mutate(`DEVELOPMENTAL STAGE` = case_when(
      grepl("larvae", trawl2020_specimen$SPECIES_DESCRIPTION) ~ "larvae",
      grepl("larva", trawl2020_specimen$SPECIES_DESCRIPTION) ~ "larva",
      grepl("adult", trawl2020_specimen$SPECIES_DESCRIPTION) ~ "adult")) %>%
  rename(eventID = sample)

trawl2020_catch_ind_scientificnames <- worrms::wm_records_names(unique(trawl2020_catch_ind$scientificname)) %>% bind_rows()
trawl2020_catch_ind_taxa <- left_join(trawl2020_catch_ind, trawl2020_catch_ind_scientificnames, by = "scientificname")
```

If 'smaller' taxa and taxa that are identified to e.g. genus or class level are included, replacing the chunk of code above with the following lines of code:

``` {r, eval = FALSE}
# trawl2020_catch_ind$identificationQualifier <- ifelse(grepl("\\b sp.\\b", trawl2020_catch_ind$scientificname),
#                                                     "sp. inc.", NA)
# trawl2020_catch_ind$occurrenceRemarks <- ifelse(grepl("\\?", trawl2020_catch_ind$scientificname), "ID not confirmed", NA)
# trawl2020_catch_ind$scientificname <- gsub("\\b sp.\\b", "", trawl2020_catch_ind$scientificname)
```

Create specificEpithet column with the species name. The individual specimen data should _not_ include species that were filtered out of the overall catch data. Therefore, now that we have adjusted all the taxa names accordingly, we have to make sure that the specimen occurrence extension only includes the taxa present in the overall catch occurrence extension. 

Finally, save the occurrence extension related to individual samples in a separate .csv file in the correct folder and on Google Drive.

``` {r, eval = FALSE}
trawl2020_catch_ind_occ <- trawl2020_catch_ind_taxa %>%
  mutate(specificEpithet = stringr::word(trawl2020_catch_ind_taxa$scientificname, 2)) %>%
  filter(!is.na(specificEpithet)) %>%
  rename(scientificNameAuthorship = authority,
         taxonomicStatus = status,
         taxonRank = rank,
         scientificName = scientificname,
         scientificNameID = lsid,
         lifeStage = `DEVELOPMENTAL STAGE`,
         sex = SEX,
         occurrenceRemarks = COMMENTS) %>%
  mutate(occurrenceID = paste(eventID, "occ", sep = ":"),
         occurrenceStatus = "present",
         individualCount = 1)

trawl2020_catch_ind_fnl <- trawl2020_catch_ind_occ %>%
  select(eventID, occurrenceID, occurrenceStatus, individualCount,
         scientificName, scientificNameID,
         scientificNameAuthorship, taxonomicStatus, taxonRank, kingdom, phylum, 
         class, order, family, genus, specificEpithet, sex, lifeStage, occurrenceRemarks)

# sex is recorded in numbers, transpose these: 1 = male, 2 = female, 3 = unclassified (as per metadata)
trawl2020_catch_ind_fnl <- trawl2020_catch_ind_fnl %>%
  mutate(sex = case_when(
    sex == "1" ~ "male",
    sex == "2" ~ "female",
    sex == "3" ~ "unclassified"))

# Save the occurrence Core locally and in Google Drive:
write_csv(trawl2020_catch_ind_fnl, here("Trawl", "2020", "tidy_data", "trawl2020_occ_ind_catch.csv"))
```

To finalize the Occurrence extension, combine the two occurrence tables. I prefer to re-order it so that it visually makes sense to me. Then, save the combined Occurrence extension locally and in Google Drive. 

``` {r trawl occurrence final, eval = FALSE}
trawl2020_Occurrence_ext <- dplyr::bind_rows(trawl2020_occ_fnl, trawl2020_catch_ind_fnl)

# To re-order the occurrenceID, use following code:
order <- stringr::str_sort(trawl2020_Occurrence_ext$occurrenceID, numeric=TRUE)
trawl2020_Occurrence_ext <- trawl2020_Occurrence_ext[match(order, trawl2020_Occurrence_ext$occurrenceID),] %>%
  mutate(basisOfRecord = "HumanObservation")

# Remove NA and replace with empty cells:
trawl2020_Occurrence_ext <- sapply(trawl2020_Occurrence_ext, as.character)
trawl2020_Occurrence_ext[is.na(trawl2020_Occurrence_ext)] <- ""
trawl2020_Occurrence_ext <- as.data.frame(trawl2020_Occurrence_ext)

# Check if occurrenceIDs are all unique - answer should be TRUE:
length(unique(trawl2020_Occurrence_ext$occurrenceID)) == nrow(trawl2020_Occurrence_ext)

# Save the occurrence Core locally and in Google Drive:
write_csv(trawl2020_Occurrence_ext, here("Trawl", "2020", "tidy_data", "trawl2020_occ_final.csv"))
```

A resource relationship extension is created to further highlight that the individual samples in the occurrence extension are part of a larger overall catch that was also listed in the occurrence extension. The required terms for this extension are `resourceID`, `relatedResourceID`, `resourceRelationshipID` and `relationshipOfResource`. The `relatedResourceID` here refers to the _object_ of the relationship, whereas the `resourceID` refers to the _subject_ of the relationship. 

The resourceRelationship extension is created separately as consensus on its use has not been reached yet. 

``` {r resourceRelationship, eval = FALSE}
trawl2020_resourceRelationship <- trawl2020_Occurrence_ext %>%
  select(eventID, occurrenceID, scientificName) %>%
  mutate(resourceID = ifelse(grepl("sample", trawl2020_Occurrence_ext$occurrenceID), trawl2020_Occurrence_ext$occurrenceID, NA)) %>%
  mutate(eventID = gsub(":sample.*", "", trawl2020_Occurrence_ext$eventID)) %>%
  group_by(eventID, scientificName) %>%
  filter(n() != 1) %>%
  ungroup()

trawl2020_resourceRelationship <- trawl2020_resourceRelationship %>%
  mutate(relatedResourceID = ifelse(grepl("sample", trawl2020_resourceRelationship$occurrenceID), NA, trawl2020_resourceRelationship$occurrenceID)) %>%
  mutate(relationshipOfResource = ifelse(!is.na(resourceID), "is a subset of", NA)) %>%
  dplyr::arrange(eventID, scientificName) %>%
  fill(relatedResourceID) %>%
  filter(!is.na(resourceID))

order <- stringr::str_sort(trawl2020_resourceRelationship$resourceID, numeric = TRUE)
trawl2020_resourceRelationship <- trawl2020_resourceRelationship[match(order, trawl2020_resourceRelationship$resourceID),]

trawl2020_resourceRelationship <- trawl2020_resourceRelationship %>%
  mutate(resourceRelationshipID = paste(relatedResourceID, "rr", sep = ":"),
         ID = sprintf("%03d", row_number()),
         resourceRelationshipID = paste(resourceRelationshipID, ID, sep = ":")) %>%
  select(eventID, resourceRelationshipID, resourceID, relationshipOfResource, relatedResourceID)

write_csv(trawl2020_resourceRelationship, here("Trawl", "2020", "tidy_data", "trawl2020_resourceRelationship.csv"))
```

To quality control whether each species in the original specimen file has been accounted for in the final, combined Occurrence extension, use the following chunk of code. We also have to check whether the unique species listed in the specimen file match the unique species listed in the overall catch file, where numbers have been aggregated. 

``` {r trawl2020_occ_check}
trawl2020_event_occ <- trawl2020_event %>% filter(!is.na(eventDate))

trawl2020_event_occ$decimalLatitude <- as.numeric(trawl2020_event_occ$decimalLatitude)
trawl2020_event_occ$decimalLongitude <- as.numeric(trawl2020_event_occ$decimalLongitude)

obistools::plot_map_leaflet(trawl2020_event_occ) # Issue: Station 20 does not have lats and longs associated
```

***

## extended MeasurementOrFact (eMOF) Extension

We create a few measurements or fact tables initially - one for the measurements pertaining to the overall catch (catch_weight), and one with the measurements pertaining to selected individuals (individual length and weight). These tables will eventually be merged into a single measurement or fact extension. 

Additionally, we need to create eMOF tables with measurements pertaining to the sampling event: trawl speed, etc. These come from the `trawl2020` dataset. Variables in the samplingEffort category are tow_speed, tow_duration, tow_distance and tow_direction. There is also data collected on bottom depth, every 15 minutes. We save these tables separately, and also combine them to form one final eMOF extension. Through the IPT, multiple eMOF extensions can be uploaded if preferred. 

```{r bottomdepth, eval = FALSE}
trawl_bottomdepth <- trawl2020 %>%
  select(eventID = trawl,
         `BOTTOM DEPTH (M) - 15 min`,
         `BOTTOM DEPTH (M) - 30 min`,
         `BOTTOM DEPTH (M) - 45 min`,
         `BOTTOM DEPTH (M) - END`) %>%
  mutate_all(as.character) %>%
  pivot_longer(cols = `BOTTOM DEPTH (M) - 15 min`:`BOTTOM DEPTH (M) - END`,
               names_to = "measurementType",
               values_to = "measurementValue") %>%
  mutate(measurementType = recode(measurementType,
                                  `BOTTOM DEPTH (M) - 15 min` = "bottom_depth_at_15_min",
                                  `BOTTOM DEPTH (M) - 30 min` = "bottom_depth_at_30_min",
                                  `BOTTOM DEPTH (M) - 45 min` = "bottom_depth_at_45_min",
                                  `BOTTOM DEPTH (M) - END` = "bottom_depth_at_end"),
         measurementTypeID = case_when(
           measurementType == "bottom_depth_at_15_min" ~ "http://vocab.nerc.ac.uk/collection/P07/current/CFSN0481/",
           measurementType == "bottom_depth_at_30_min" ~ "http://vocab.nerc.ac.uk/collection/P07/current/CFSN0481/",
           measurementType == "bottom_depth_at_45_min" ~ "http://vocab.nerc.ac.uk/collection/P07/current/CFSN0481/",
           measurementType == "bottom_depth_at_end" ~ "http://vocab.nerc.ac.uk/collection/P07/current/CFSN0481/"),
         # Perhaps this is better: http://vocab.nerc.ac.uk/collection/A05/current/EV_BATHY/
         measurementUnit = case_when(
           measurementType == "bottom_depth_at_15_min" ~ "meters",
           measurementType == "bottom_depth_at_30_min" ~ "meters",
           measurementType == "bottom_depth_at_45_min" ~ "meters",
           measurementType == "bottom_depth_at_end" ~ "meters"),
         measurementUnitID = case_when(
           measurementUnit == "meters" ~ "http://vocab.nerc.ac.uk/collection/P06/current/ULAA/"),
         measurementValueID = NA,
         measurementID = paste(eventID, measurementType, sep = ":")) %>%
  select(eventID, measurementID, measurementType, measurementTypeID, measurementValue, measurementValueID,
         measurementUnit, measurementUnitID)

# Save the bottom depth extension locally:
write_csv(trawl_bottomdepth, here("Trawl", "2020", "tidy_data", "trawl2020_bottomdepth_emof.csv"))
```

Measurements pertaining to the sampling effort: 

```{r samplingEffort, eval = FALSE}
samplingEffort <- trawl2020 %>%
  select(eventID = trawl,
         `DURATION OF TOW (min)`,
         `DIRECTION OF SET (TRUE) - 15 min`,
         `DIRECTION OF SET (TRUE) - 30 min`,
         `DIRECTION OF SET (TRUE) - 45 min`, 
         `DIRECTION OF SET (TRUE) - END`,
         `SPEED (Kn) - 15 min`,
         `SPEED (Kn) - 30 min`,
         `SPEED (Kn) - 45 min`,
         `SPEED (Kn) - END`,
         `DISTANCE OF FISHING OPERATION (nm)`)%>%
  mutate_all(as.character) %>%
  pivot_longer(cols = `DURATION OF TOW (min)`:`DISTANCE OF FISHING OPERATION (nm)`,
               names_to = "measurementType",
               values_to = "measurementValue") %>%
  mutate(measurementType = recode(measurementType,
         `DURATION OF TOW (min)` = "tow_duration",
         `DIRECTION OF SET (TRUE) - 15 min` = "direction_of_set_at_15_min",
         `DIRECTION OF SET (TRUE) - 30 min` = "direction_of_set_at_30_min",
         `DIRECTION OF SET (TRUE) - 45 min` = "direction_of_set_at_45_min", 
         `DIRECTION OF SET (TRUE) - END` = "direction_of_set_at_end",
         `SPEED (Kn) - 15 min` = "vessel_speed_at_15_min",
         `SPEED (Kn) - 30 min` = "vessel_speed_at_30_min",
         `SPEED (Kn) - 45 min` = "vessel_speed_at_45_min",
         `SPEED (Kn) - END` = "vessel_speed_at_end",
         `DISTANCE OF FISHING OPERATION (nm)` = "tow_distance"),
         measurementTypeID = case_when(
           measurementType == "tow_duration" ~ "http://vocab.nerc.ac.uk/collection/P01/current/AZDRZZ01/",
           measurementType == "direction_of_set_at_15_min" ~ "http://vocab.nerc.ac.uk/collection/P07/current/CFSN0481/",
           measurementType == "direction_of_set_at_30_min" ~ "http://vocab.nerc.ac.uk/collection/P07/current/CFSN0481/",
           measurementType == "direction_of_set_at_45_min" ~ "http://vocab.nerc.ac.uk/collection/P07/current/CFSN0481/",
           measurementType == "direction_of_set_at_end" ~ "http://vocab.nerc.ac.uk/collection/P07/current/CFSN0481/",
           measurementType == "vessel_speed_at_15_min" ~ "http://vocab.nerc.ac.uk/collection/P01/current/TOWSPEED/",
           measurementType == "vessel_speed_at_30_min" ~ "http://vocab.nerc.ac.uk/collection/P01/current/TOWSPEED/",
           measurementType == "vessel_speed_at_45_min" ~ "http://vocab.nerc.ac.uk/collection/P01/current/TOWSPEED/",
           measurementType == "vessel_speed_at_end" ~ "http://vocab.nerc.ac.uk/collection/P01/current/TOWSPEED/",
           measurementType == "tow_distance" ~ "http://vocab.nerc.ac.uk/collection/P01/current/LENTRACK/"),
         measurementUnit = case_when(
           measurementType == "tow_duration" ~ "minutes",
           measurementType == "direction_of_set_at_15_min" ~ "degrees",
           measurementType == "direction_of_set_at_30_min" ~ "degrees",
           measurementType == "direction_of_set_at_45_min" ~ "degrees",
           measurementType == "direction_of_set_at_end" ~ "degrees",
           measurementType == "vessel_speed_at_15_min" ~ "knots",
           measurementType == "vessel_speed_at_30_min" ~ "knots",
           measurementType == "vessel_speed_at_45_min" ~ "knots",
           measurementType == "vessel_speed_at_end" ~ "knots",
           measurementType == "tow_distance" ~ "nautical miles"),
         measurementUnitID = case_when(
           measurementUnit == "minutes" ~ "http://vocab.nerc.ac.uk/collection/P06/current/UMIN/",
           measurementUnit == "degrees" ~ "http://vocab.nerc.ac.uk/collection/P06/current/UABB/",
           measurementUnit == "knots" ~ "http://vocab.nerc.ac.uk/collection/P06/current/UKNT/"),
         measurementValueID = NA,
         measurementID = paste(eventID, measurementType, sep = ":")
         ) %>%
  select(eventID, measurementID, measurementType, measurementTypeID, measurementValue, measurementValueID,
         measurementUnit, measurementUnitID)

# Save the occurrence Core locally and in Google Drive:
write_csv(samplingEffort, here("Trawl", "2020", "tidy_data", "trawl2020_samplingEffort_emof.csv"))
```

And chunk of code to assign sampling instrument measurements/facts:

```{r samplingInstrument, eval = FALSE}
samplingInstrument <- trawl2020 %>%
  select(eventID = trawl,
         GEAR,
         `HEADROPE DEPTH (M) - 15 min`,
         `HEADROPE DEPTH (M) - 30 min`, 
         `HEADROPE DEPTH (M) - 45 min`,
         `HEADROPE DEPTH (M) - END`,
         `WARP DISTANCE (M) - 15 min`,
         `WARP DISTANCE (M) - 30 min`,
         `WARP DISTANCE (M) - 45 min`,
         `WARP DISTANCE (M) - END`,
         `NET OPENING WIDTH (M) - Wing tips`,
         `NET OPENING WIDTH (M) - Wing tips - 30 min`,
         `NET OPENING WIDTH (M) - Wing tips - 45 min`,
         `NET OPENING WIDTH (M) - Wing tips - END`,
         `NET OPENING WIDTH (M) - Doors`,
         `NET OPENING WIDTH (M) - Doors - 30 min`,
         `NET OPENING WIDTH (M) - Doors - 45 min`,
         `NET OPENING WIDTH (M) - Doors - END`,
         `NET OPENING DEPTH (metres) - 15 min`,
         `NET OPENING DEPTH (metres) - 30 min`,
         `NET OPENING DEPTH (metres) - 45 min`,
         `NET OPENING DEPTH (metres) - END`) %>%
  mutate_all(as.character) %>%
  pivot_longer(cols = `GEAR`:`NET OPENING DEPTH (metres) - END`,
               names_to = "measurementType",
               values_to = "measurementValue") %>%
  mutate(measurementType = recode(measurementType,
         GEAR = "sampling_gear",
         `HEADROPE DEPTH (M) - 15 min` = "headrope_depth_15_min",
         `HEADROPE DEPTH (M) - 30 min` = "headrope_depth_30_min",
         `HEADROPE DEPTH (M) - 45 min` = "headrope_depth_45_min",
         `HEADROPE DEPTH (M) - END` = "headrope_depth_end",
         `WARP DISTANCE (M) - 15 min` = "warp_distance_15_min",
         `WARP DISTANCE (M) - 30 min` = "warp_distance_30_min",
         `WARP DISTANCE (M) - 45 min` = "warp_distance_45_min",
         `WARP DISTANCE (M) - END` = "warp_distance_end",
         `NET OPENING WIDTH (M) - Wing tips` = "net_opening_width_wings",
         `NET OPENING WIDTH (M) - Wing tips - 30 min` = "net_opening_width_wings_30_min",
         `NET OPENING WIDTH (M) - Wing tips - 45 min` = "net_opening_width_wings_45_min",
         `NET OPENING WIDTH (M) - Wing tips - END` = "net_opening_width_wings_end",
         `NET OPENING WIDTH (M) - Doors` = "net_opening_width_doors",
         `NET OPENING WIDTH (M) - Doors - 30 min` = "net_opening_width_doors_30_min",
         `NET OPENING WIDTH (M) - Doors - 45 min` = "net_opening_width_doors_45_min",
         `NET OPENING WIDTH (M) - Doors - END` = "net_opening_width_doors_end",
         `NET OPENING DEPTH (metres) - 15 min` = "net_opening_depth_15_min",
         `NET OPENING DEPTH (metres) - 30 min` = "net_opening_depth_30_min",
         `NET OPENING DEPTH (metres) - 45 min` = "net_opening_depth_45_min",
         `NET OPENING DEPTH (metres) - END` = "net_opening_depth_end"),
         measurementTypeID = case_when(
           measurementType == "sampling_gear" ~ "http://vocab.nerc.ac.uk/collection/Q01/current/Q0100002/",
           measurementType == "net_opening_width_wings" ~ " ",
           measurementType == "net_opening_width_wings_30_min" ~ " ",
           measurementType == "net_opening_width_wings_45_min" ~ " ",
           measurementType == "net_opening_width_wings_end" ~ " ",
           measurementType == "headrope_depth_15_min" ~ " ",
           measurementType == "headrope_depth_30_min" ~ " ",
           measurementType == "headrope_depth_45_min" ~ " ",
           measurementType == "headrope_depth_end" ~ " ",
           measurementType == "warp_distance_15_min" ~ " ",
           measurementType == "warp_distance_30_min" ~ " ",
           measurementType == "warp_distance_45_min" ~ " ",
           measurementType == "warp_distance_end" ~ " ",
           measurementType == "net_opening_width_doors" ~ "http://vocab.nerc.ac.uk/collection/Q01/current/Q0100014/",
           measurementType == "net_opening_width_doors_30_min" ~ "http://vocab.nerc.ac.uk/collection/Q01/current/Q0100014/",
           measurementType == "net_opening_width_doors_45_min" ~ "http://vocab.nerc.ac.uk/collection/Q01/current/Q0100014/",
           measurementType == "net_opening_width_doors_end" ~ "http://vocab.nerc.ac.uk/collection/Q01/current/Q0100014/",
           measurementType == "net_opening_depth_15_min" ~ "http://vocab.nerc.ac.uk/collection/Q01/current/Q0100013/",
           measurementType == "net_opening_depth_30_min" ~ "http://vocab.nerc.ac.uk/collection/Q01/current/Q0100013/",
           measurementType == "net_opening_depth_45_min" ~ "http://vocab.nerc.ac.uk/collection/Q01/current/Q0100013/",
           measurementType == "net_opening_depth_end" ~ "http://vocab.nerc.ac.uk/collection/Q01/current/Q0100013/"),
         measurementUnit = case_when(
           measurementType != "sampling_gear" ~ "meters"),
         measurementUnitID = case_when(
           measurementUnit == "meters" ~ "http://vocab.nerc.ac.uk/collection/P06/current/ULAA/"),
         measurementValueID = case_when(
           measurementType == "sampling_gear" ~ " "),
         measurementID = paste(eventID, measurementType, sep = ":")) %>%
  select(eventID, measurementID, measurementType, measurementTypeID, measurementValue, measurementValueID,
         measurementUnit, measurementUnitID)

# Save the extended measurementOrFact extension locally and in Google Drive:
write_csv(samplingInstrument, here("Trawl", "2020", "tidy_data", "trawl2020_samplingInstrument_emof.csv"))
```

And a chunk of code to assign environmental conditions during the trawl:

```{r environmental conditions, eval = FALSE}
trawl_conditions <- trawl2020 %>%
  select(eventID = trawl,
         `WAVE HEIGHT (m)`,
         `SWELL HEIGHT (m)`, 
         `SEA STATE DESCRIPTION`,
         `TEMPERATURE @ NET (oC) - 15 min`,
         `TEMPERATURE @ NET (oC) - 30 min`,
         `TEMPERATURE @ NET (oC) - 45 min`,
         `TEMPERATURE @ NET (oC) - END`,
         `WIND DIRECTION (degrees)`,
         `WIND SPEED (knots)`,
         `CLOUD/WEATHER`) %>%
  mutate_all(as.character) %>%
  pivot_longer(cols = `WAVE HEIGHT (m)`:`CLOUD/WEATHER`,
               names_to = "measurementType",
               values_to = "measurementValue") %>%
  mutate(measurementType = recode(measurementType,
                                  `WAVE HEIGHT (m)` = "wave_height",
                                  `SWELL HEIGHT (m)` = "swell_height",
                                  `SEA STATE DESCRIPTION` = "sea_state_description",
                                  `TEMPERATURE @ NET - 15 min` = "temperature_at_net_15_min",
                                  `TEMPERATURE @ NET - 30 min` = "temperature_at_net_30_min",
                                  `TEMPERATURE @ NET - 45 min` = "temperature_at_net_45_min",
                                  `TEMPERATURE @ NET - END` = "temperature_at_net_end",
                                  `WIND DIRECTION (degrees)` = "wind_direction",
                                  `WIND SPEED (knots)` = "wind_speed",
                                  `CLOUD/WEATHER` = "weather_description"),
         measurementTypeID = case_when(
           measurementType == "wave_height" ~ "http://vocab.nerc.ac.uk/collection/P07/current/JNQS0CMX/",
           measurementType == "swell_height" ~ "http://vocab.nerc.ac.uk/collection/P09/current/SWHT/",
           measurementType == "sea_state_description" ~ " ",
           measurementType == "temperature_at_net_15_min" ~ " ",
           measurementType == "temperature_at_net_30_min" ~ " ",
           measurementType == "temperature_at_net_45_min" ~ " ",
           measurementType == "temperature_at_net_end" ~ " ",
           measurementType == "wind_direction" ~ "http://vocab.nerc.ac.uk/collection/B39/current/relwinddir/",
           measurementType == "wind_speed" ~ "http://vocab.nerc.ac.uk/collection/P07/current/CFSN0038/",
           measurementType == "weather_description" ~ " "),
         measurementUnit = case_when(
           measurementType == "wave_height" ~ "meters",
           measurementType == "swell_height" ~ "meters",
           measurementType == "wind_direction" ~ "degrees",
           measurementType == "wind_speed" ~ "knots",
           measurementType == "temperature_at_net_15_min" ~ "degrees celsius",
           measurementType == "temperature_at_net_30_min" ~ "degrees celsius",
           measurementType == "temperature_at_net_45_min" ~ "degrees celsius",
           measurementType == "temperature_at_net_end" ~ "degrees celsius"),
         measurementUnitID = case_when(
           measurementUnit == "meters" ~ "http://vocab.nerc.ac.uk/collection/P06/current/ULAA/",
           measurementUnit == "degrees" ~ "http://vocab.nerc.ac.uk/collection/P06/current/UAAA/",
           measurementUnit == "knots" ~ "http://vocab.nerc.ac.uk/collection/P06/current/UKNT/",
           measurementUnit == "degrees celsius" ~ "http://vocab.nerc.ac.uk/collection/P06/current/UPAA/"
         ),
         measurementValueID = NA,
         measurementID = paste(eventID, measurementType, sep = ":")) %>% 
  select(eventID, measurementID, measurementType, measurementTypeID, measurementValue, measurementValueID,
         measurementUnit, measurementUnitID)

# Save the occurrence Core locally and in Google Drive:
write_csv(trawl_conditions, here("Trawl", "2020", "tidy_data", "trawl2020_conditions_emof.csv"))
```

Next two eMOF extensions are created with measurements pertaining to overall species' catch weight at each trawl, and individual length and weight measurements.

```{r eMoF}
trawl2020_allcatch_measurement <- trawl2020_occ %>%
  select(eventID, 
         occurrenceID,
         individualCount,
         `CATCH_WEIGHT (KG)`) %>%
  mutate_all(as.character) %>%
  pivot_longer(cols = c(individualCount, `CATCH_WEIGHT (KG)`),
               names_to = "measurementType",
               values_to = "measurementValue") %>%
  mutate(measurementMethod = ifelse(measurementType == "individualCount", "total", NA))

trawl2020_allcatch_emof <- trawl2020_allcatch_measurement %>% 
  mutate(measurementType = recode(measurementType,
                                  `CATCH_WEIGHT (KG)` = "Total species biomass",
                                  organismQuantity = "individualCount"),
         measurementID = case_when(
           measurementType == "individualCount" ~ paste(occurrenceID, "individualCount", sep = ":"),
           measurementType == "Total species biomass" ~ paste(occurrenceID, "biomass", sep = ":")),
         measurementTypeID = case_when(
           measurementType == "Total species biomass" ~ "http://vocab.nerc.ac.uk/collection/S06/current/S0600088/",
           measurementType == "individualCount" ~ "http://vocab.nerc.ac.uk/collection/P01/current/OCOUNT01/"),
         measurementUnit = case_when(
           measurementType == "Total species biomass" ~ "kilogram",
           measurementType == "individualCount" ~ "individuals"),
         measurementUnitID = case_when(
           measurementUnit == "kilogram" ~ "http://vocab.nerc.ac.uk/collection/P06/current/KGXX/",
           measurementUnit == "individuals" ~ "http://vocab.nerc.ac.uk/collection/P06/current/UUUU/"),
         measurementValueID = NA) %>%
  select(eventID, occurrenceID, measurementID, measurementType, measurementTypeID, measurementValue, measurementValueID,
         measurementUnit, measurementUnitID, measurementMethod)
```

Next, create the measurementOrFact extension with length and weight measurements assigned to the _individual_ specimens. 

``` {r}
trawl2020_ind_emof <- trawl2020_catch_ind_occ %>%
  select(eventID, 
         occurrenceID,
         `LENGTH (FORK) - mm`:`WEIGHT - ROUND (g)`) %>%
  mutate_all(as.character) %>%
  pivot_longer(cols = `LENGTH (FORK) - mm`:`WEIGHT - ROUND (g)`,
               names_to = "measurementType",
               values_to = "measurementValue") %>%
  mutate(measurementType = recode(measurementType,
                                  `LENGTH (FORK) - mm` = "Fork length",
                                  `LENGTH (STANDARD) - mm` = "Standard length",
                                  `LENGTH (TOTAL)` = "Total length",
                                  `LENGTH (MANTLE) - cm` = "Mantle length",
                                  `WEIGHT - ROUND (g)` = "weight"),
         measurementID = case_when(
           measurementType == "Fork length" ~ paste(occurrenceID, "fork_length", sep = ":"),
           measurementType == "Standard length" ~ paste(occurrenceID, "standard_length", sep = ":"),
           measurementType == "Total length" ~ paste(occurrenceID, "total_length", sep = ":"),
           measurementType == "Mantle length" ~ paste(occurrenceID, "mantle_length", sep = ":"),
           measurementType == "weight" ~ paste(occurrenceID, "weight", sep = ":")),
         measurementTypeID = case_when(
           measurementType == "Fork length" ~ "http://vocab.nerc.ac.uk/collection/P01/current/FL01XX01/",
           measurementType == "Standard length" ~ "http://vocab.nerc.ac.uk/collection/P01/current/SL01XX01/",
           measurementType == "Total length" ~ "http://vocab.nerc.ac.uk/collection/P01/current/TL01XX01/",
           measurementType == "Mantle length" ~ "http://vocab.nerc.ac.uk/collection/P01/current/DML1XX01/",
           measurementType == "weight" ~ "http://vocab.nerc.ac.uk/collection/S06/current/S0600088/"),
         measurementUnit = case_when(
           measurementType == "Fork length" ~ "millimeters",
           measurementType == "Standard length" ~ "millimeters",
           measurementType == "Total length" ~ "millimeters",
           measurementType == "Mantle length" ~ "centimeters",
           measurementType == "weight" ~ "grams"),
         measurementUnitID = case_when(
           measurementUnit == "millimeters" ~ "http://vocab.nerc.ac.uk/collection/P06/current/UXMM/",
           measurementUnit == "centimeters" ~ "http://vocab.nerc.ac.uk/collection/P06/current/ULCM/",
           measurementUnit == "grams" ~ "http://vocab.nerc.ac.uk/collection/P06/current/UGRM/")) %>%
  mutate(measurementValueID = NA) %>%
  drop_na(measurementValue) %>%
  select(eventID, occurrenceID, measurementID, measurementType, measurementTypeID, measurementValue, measurementValueID,
         measurementUnit, measurementUnitID)
```

Combine the two extended measurementOrFact extensions into a single eMOF extension, and save locally and in GoogleDrive:

``` {r}
trawl2020_eMOF <- dplyr::bind_rows(trawl2020_allcatch_emof, trawl2020_ind_emof)

# To combine all the extensions, use: 
# trawl2020_all_emofs <- dplyr::bind_rows(trawl_bottomdepth, samplingEffort, samplingInstrument, trawl_conditions, trawl2020_allcatch_emof, trawl2020_ind_emof)

# Remove NA and replace with empty cells:
trawl2020_eMOF <- sapply(trawl2020_eMOF, as.character)
trawl2020_eMOF[is.na(trawl2020_eMOF)] <- ""
trawl2020_eMOF <- as.data.frame(trawl2020_eMOF)

write_csv(trawl2020_eMOF, here("Trawl", "2020", "tidy_data", "trawl2020_eMOF.csv"))
drive_upload(here("Trawl", "tidy_data", "trawl_emof.csv"),
             path = "https://drive.google.com/drive/folders/1ZbvwjD8odJr2SUKq6Z8zAwpLd6QeOOYC",
             name = "trawl_eMoF.csv",
             overwrite = TRUE)
```